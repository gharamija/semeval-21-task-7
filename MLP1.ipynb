{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c748ad37",
   "metadata": {},
   "source": [
    "# MLP model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72d15a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c10d2e",
   "metadata": {},
   "source": [
    "### Puni dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4dc4ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7996</td>\n",
       "      <td>Lack of awareness of the pervasiveness of raci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7997</td>\n",
       "      <td>Why are aspirins white? Because they work sorry</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7998</td>\n",
       "      <td>Today, we Americans celebrate our independence...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7999</td>\n",
       "      <td>How to keep the flies off the bride at an Ital...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>8000</td>\n",
       "      <td>\"Each ounce of sunflower seeds gives you 37% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "0        1  TENNESSEE: We're the best state. Nobody even c...         1   \n",
       "1        2  A man inserted an advertisement in the classif...         1   \n",
       "2        3  How many men does it take to open a can of bee...         1   \n",
       "3        4  Told my mom I hit 1200 Twitter followers. She ...         1   \n",
       "4        5  Roses are dead. Love is fake. Weddings are bas...         1   \n",
       "...    ...                                                ...       ...   \n",
       "7995  7996  Lack of awareness of the pervasiveness of raci...         0   \n",
       "7996  7997    Why are aspirins white? Because they work sorry         1   \n",
       "7997  7998  Today, we Americans celebrate our independence...         1   \n",
       "7998  7999  How to keep the flies off the bride at an Ital...         1   \n",
       "7999  8000  \"Each ounce of sunflower seeds gives you 37% o...         0   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  \n",
       "0             2.42                1.0            0.20  \n",
       "1             2.50                1.0            1.10  \n",
       "2             1.95                0.0            2.40  \n",
       "3             2.11                1.0            0.00  \n",
       "4             2.78                0.0            0.10  \n",
       "...            ...                ...             ...  \n",
       "7995           NaN                NaN            0.25  \n",
       "7996          1.33                0.0            3.85  \n",
       "7997          2.55                0.0            0.00  \n",
       "7998          1.00                0.0            3.00  \n",
       "7999           NaN                NaN            0.00  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3f3a7",
   "metadata": {},
   "source": [
    "Značenje stupaca:\n",
    "\n",
    "    - id - Ovo je identifikacijski broj za svaku recenicu. Može se koristiti za jedinstveno identificiranje svake stavke u skupu podataka.\n",
    "    - text - Ovaj stupac sadrži rečenice koje je potrebno analizirati.\n",
    "    - is_humor - inarna oznaka (0 ili 1) koja označava ima li rečenica humor ili ne. Ako je vrijednost 1, rečenica je označena kao humoristična, ako je 0, rečenica nije .\n",
    "    - humor_rating - Numerička ocjena (1-5) koja predstavlja subjektivnu percepciju anotatora o tome koliko je rečenica smiješna. Anotatori su ocijenili smiješnost rečenice na skali od 1 do 5.\n",
    "    - humor_controversy - Binarna oznaka (0 ili 1) koja označava ima li kontroverzu humora u rečenici. Ako je vrijednost 1, to znači da je ocjena humora za tu rečenicu kontroverzna.\n",
    "    - offense_rating - Numerička ocjena (1-5) koja predstavlja subjektivnu percepciju anotatora o tome koliko je rečenica uvredljiva. Anotatori su ocijenili razinu uvredljivosti rečenice na skali od 1 do 5. Ovdje se također razmatra da nedavanje ocjene jednako 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4153fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id     is_humor  humor_rating  humor_controversy  \\\n",
      "count  8000.00000  8000.000000   4932.000000        4932.000000   \n",
      "mean   4000.50000     0.616500      2.260525           0.499797   \n",
      "std    2309.54541     0.486269      0.566974           0.500051   \n",
      "min       1.00000     0.000000      0.100000           0.000000   \n",
      "25%    2000.75000     0.000000      1.890000           0.000000   \n",
      "50%    4000.50000     1.000000      2.280000           0.000000   \n",
      "75%    6000.25000     1.000000      2.650000           1.000000   \n",
      "max    8000.00000     1.000000      4.000000           1.000000   \n",
      "\n",
      "       offense_rating  \n",
      "count     8000.000000  \n",
      "mean         0.585325  \n",
      "std          0.979955  \n",
      "min          0.000000  \n",
      "25%          0.000000  \n",
      "50%          0.100000  \n",
      "75%          0.700000  \n",
      "max          4.850000  \n",
      "\n",
      "\n",
      "Broj humoristicnih tekstova: 4932\n",
      "Broj ne humoristicnih: 3068\n",
      "Broj NaN zapisa: 0\n",
      "Broj NaN zapisa: 3068\n",
      "Broj NaN zapisa: 3068\n",
      "Broj NaN zapisa: 0\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())\n",
    "print()\n",
    "print()\n",
    "print(f\"Broj humoristicnih tekstova: {len(data[data['is_humor'] == 1])}\")\n",
    "print(f\"Broj ne humoristicnih: {len(data[data['is_humor'] == 0])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['is_humor'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['humor_rating'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['humor_controversy'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['offense_rating'].isna()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3861331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj redaka bez NaN vrijednosti u 'text' stupcu: 8000\n"
     ]
    }
   ],
   "source": [
    "# Provjerava ima li unos u svakom redu za 'text' stupac\n",
    "text_column_not_null = data['text'].dropna()\n",
    "\n",
    "# Ispisuje duljinu rezultirajućeg DataFrame-a\n",
    "print(f\"Broj redaka bez NaN vrijednosti u 'text' stupcu: {len(text_column_not_null)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8d34ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udio kontroverznosti humora: 30.81%\n"
     ]
    }
   ],
   "source": [
    "# Udio kontroverznosti humora\n",
    "controversial_count = data['humor_controversy'].sum()\n",
    "total_samples = len(data)\n",
    "\n",
    "print(f\"Udio kontroverznosti humora: {controversial_count / total_samples * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39757bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentence_length\n",
      "0  TENNESSEE: We're the best state. Nobody even c...               17\n",
      "1  A man inserted an advertisement in the classif...               32\n",
      "2  How many men does it take to open a can of bee...               26\n",
      "3  Told my mom I hit 1200 Twitter followers. She ...               26\n",
      "4  Roses are dead. Love is fake. Weddings are bas...               12\n",
      "sentence_length    20.889375\n",
      "dtype: float64\n",
      "is_humor\n",
      "0    21.932855\n",
      "1    20.240268\n",
      "Name: sentence_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analiza duljine rečenica\n",
    "data['sentence_length'] = data['text'].apply(lambda x: len(x.split()))\n",
    "print(data[['text', 'sentence_length']].head())\n",
    "print(data[['sentence_length']].mean())\n",
    "print(data.groupby('is_humor')['sentence_length'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72dbc6",
   "metadata": {},
   "source": [
    "Training set ne sadrži neispravne primjere. Gdje su vrijednosti is_humor == 0, tj. za tekstove koji nisu humoristični nema vrijednosti humor_rating\ti humor_controversy jer to za njih niti nije moguće izračunati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40bbb0",
   "metadata": {},
   "source": [
    "### Podjela dataset-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "06ec1279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 6400\n",
      "Size of dev set: 800\n",
      "Size of test set: 800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Assuming you have a dataframe 'data' with features and labels\n",
    "# X contains your features, y contains your labels\n",
    "\n",
    "# Create an instance of StratifiedShuffleSplit for splitting into train and temp sets\n",
    "stratified_splitter_train_temp = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the splitter to generate indices for train and temp sets\n",
    "for train_index, temp_index in stratified_splitter_train_temp.split(data, data['is_humor']):\n",
    "    train_data, temp_data = data.iloc[train_index], data.iloc[temp_index]\n",
    "\n",
    "# Create an instance of StratifiedShuffleSplit for further splitting temp into dev and test sets\n",
    "stratified_splitter_temp_dev_test = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "# Use the splitter to generate indices for dev and test sets\n",
    "for dev_index, test_index in stratified_splitter_temp_dev_test.split(temp_data, temp_data['is_humor']):\n",
    "    dev_data, test_data = temp_data.iloc[dev_index], temp_data.iloc[test_index]\n",
    "\n",
    "# Print the sizes of the obtained sets\n",
    "print(f\"Size of train set: {len(train_data)}\")\n",
    "print(f\"Size of dev set: {len(dev_data)}\")\n",
    "print(f\"Size of test set: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "578e77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spremi train set u CSV file\n",
    "train_data.to_csv('data/train.csv', index=False)\n",
    "\n",
    "# Spremi dev set u CSV file\n",
    "dev_data.to_csv('data/dev.csv', index=False)\n",
    "\n",
    "# Spremi test set u CSV file\n",
    "test_data.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f408b0",
   "metadata": {},
   "source": [
    "### Odnos humorističnih i nehumorističnih tekstova u train i dev setu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "be9b16fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>5739</th>\n",
       "      <td>5740</td>\n",
       "      <td>I left my wife because she was obsessed with c...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5864</th>\n",
       "      <td>5865</td>\n",
       "      <td>\"Procrastinate\" comes from a Latin word meanin...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5753</th>\n",
       "      <td>5754</td>\n",
       "      <td>if school taught me to say no to fast food ins...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4321</th>\n",
       "      <td>4322</td>\n",
       "      <td>I just realized my countertop is made of marbl...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.79</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>786</th>\n",
       "      <td>787</td>\n",
       "      <td>What are your best resources or most recommend...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1104</th>\n",
       "      <td>1105</td>\n",
       "      <td>Girls who talks about girls' problems are grea...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.29</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.70</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6059</th>\n",
       "      <td>6060</td>\n",
       "      <td>I'm trying to introduce my wife to my Scooby D...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.35</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7878</th>\n",
       "      <td>7879</td>\n",
       "      <td>I created a show about an airplane hijacking. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.74</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.20</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7598</th>\n",
       "      <td>7599</td>\n",
       "      <td>I find sex is just like peeling a potato reall...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.85</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>17</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2820</th>\n",
       "      <td>2821</td>\n",
       "      <td>\"It takes a great deal of bravery to stand up ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>27</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "5739  5740  I left my wife because she was obsessed with c...         1   \n",
       "5864  5865  \"Procrastinate\" comes from a Latin word meanin...         0   \n",
       "5753  5754  if school taught me to say no to fast food ins...         1   \n",
       "4321  4322  I just realized my countertop is made of marbl...         1   \n",
       "786    787  What are your best resources or most recommend...         0   \n",
       "...    ...                                                ...       ...   \n",
       "1104  1105  Girls who talks about girls' problems are grea...         1   \n",
       "6059  6060  I'm trying to introduce my wife to my Scooby D...         1   \n",
       "7878  7879  I created a show about an airplane hijacking. ...         1   \n",
       "7598  7599  I find sex is just like peeling a potato reall...         1   \n",
       "2820  2821  \"It takes a great deal of bravery to stand up ...         0   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  sentence_length  \n",
       "5739          1.95                1.0            0.00               17  \n",
       "5864           NaN                NaN            0.00               26  \n",
       "5753          2.40                0.0            0.15               25  \n",
       "4321          2.79                1.0            0.00               17  \n",
       "786            NaN                NaN            0.00               18  \n",
       "...            ...                ...             ...              ...  \n",
       "1104          2.29                1.0            0.70               17  \n",
       "6059          2.25                1.0            0.35               36  \n",
       "7878          2.74                0.0            1.20               13  \n",
       "7598          1.85                1.0            1.80               17  \n",
       "2820           NaN                NaN            0.00               27  \n",
       "\n",
       "[6400 rows x 7 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ec291252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postotak humorističnih tekstova u train setu: 61.66%\n",
      "Postotak nehumorističnih tekstova u train setu: 38.34%\n"
     ]
    }
   ],
   "source": [
    "# Broj humorističnih tekstova u train setu\n",
    "humor_percent = len(train_data[train_data['is_humor'] == 1]) / len(train_data) * 100\n",
    "\n",
    "# Broj nehumorističnih tekstova u train setu\n",
    "non_humor_percent = len(train_data[train_data['is_humor'] == 0]) / len(train_data) * 100\n",
    "\n",
    "# Ispis rezultata s dvije decimale\n",
    "print(f\"Postotak humorističnih tekstova u train setu: {humor_percent:.2f}%\")\n",
    "print(f\"Postotak nehumorističnih tekstova u train setu: {non_humor_percent:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "dcdfa08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1865</td>\n",
       "      <td>Me: What are my chances doc? Doctor: The surge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>7236</td>\n",
       "      <td>Why do fish live in salt water? Because pepper...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>2688</td>\n",
       "      <td>Family, we appreciate your patience. Due to fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1455</td>\n",
       "      <td>John F. Kennedy's brain has been missing for 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>7831</td>\n",
       "      <td>\"Blueberry juice boosts memory\"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1804</td>\n",
       "      <td>On a daily basis some young gay guys get HIV t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>4750</td>\n",
       "      <td>just had a redbull, feelin' good, energetic, m...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>2141</td>\n",
       "      <td>We would like to remind you that registration ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>4141</td>\n",
       "      <td>I'm a big fan of people being exactly who they...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>750</td>\n",
       "      <td>Everybody's a gangster until they get punched ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "1864  1865  Me: What are my chances doc? Doctor: The surge...         1   \n",
       "7235  7236  Why do fish live in salt water? Because pepper...         1   \n",
       "2687  2688  Family, we appreciate your patience. Due to fu...         0   \n",
       "1454  1455  John F. Kennedy's brain has been missing for 5...         1   \n",
       "7830  7831                    \"Blueberry juice boosts memory\"         0   \n",
       "...    ...                                                ...       ...   \n",
       "1803  1804  On a daily basis some young gay guys get HIV t...         0   \n",
       "4749  4750  just had a redbull, feelin' good, energetic, m...         0   \n",
       "2140  2141  We would like to remind you that registration ...         0   \n",
       "4140  4141  I'm a big fan of people being exactly who they...         0   \n",
       "749    750  Everybody's a gangster until they get punched ...         1   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  sentence_length  \n",
       "1864          2.40                1.0            0.00               32  \n",
       "7235          2.60                1.0            0.00               13  \n",
       "2687           NaN                NaN            0.00               46  \n",
       "1454          1.27                0.0            1.55               10  \n",
       "7830           NaN                NaN            0.05                4  \n",
       "...            ...                ...             ...              ...  \n",
       "1803           NaN                NaN            0.00               51  \n",
       "4749           NaN                NaN            0.00               22  \n",
       "2140           NaN                NaN            0.20               22  \n",
       "4140           NaN                NaN            0.00               16  \n",
       "749           2.89                1.0            0.25               19  \n",
       "\n",
       "[800 rows x 7 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "37a925dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postotak humorističnih tekstova u dev setu: 61.62%\n",
      "Postotak nehumorističnih tekstova u dev setu: 38.38%\n"
     ]
    }
   ],
   "source": [
    "# Broj humorističnih tekstova u dev setu\n",
    "humor_percent = len(dev_data[dev_data['is_humor'] == 1]) / len(dev_data) * 100\n",
    "\n",
    "# Broj nehumorističnih tekstova u dev setu\n",
    "non_humor_percent = len(dev_data[dev_data['is_humor'] == 0]) / len(dev_data) * 100\n",
    "\n",
    "# Ispis rezultata s dvije decimale\n",
    "print(f\"Postotak humorističnih tekstova u dev setu: {humor_percent:.2f}%\")\n",
    "print(f\"Postotak nehumorističnih tekstova u dev setu: {non_humor_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46e584",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b09d18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\josip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\josip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351503d",
   "metadata": {},
   "source": [
    "#### Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d844ec7a",
   "metadata": {},
   "source": [
    "In order to use Word2Vec, you need to pre-process the data. It's very simple: you just need to split sentences to words (tokenization), bring the words to their basic form (lemmatization), and remove some very common words like articles or prepositions (stop-word removal). I'm using RegexpTokenizer, WordNetLemmatizer and NLTK stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6fe786d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "23efeb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "a040fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f1fb7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['processed_text'], \n",
    "    data['is_humor'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "bd774026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model training\n",
    "word2vec_model = Word2Vec(sentences=X_train.apply(word_tokenize), vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "73b71216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average word vectors for a sentence\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            n_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    if n_words:\n",
    "        feature_vector = np.divide(feature_vector, n_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "718f06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data to Word2Vec features\n",
    "def word2vec_features(data, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    return np.vstack([average_word_vectors(tokens, model, vocabulary, num_features) for tokens in data.apply(word_tokenize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6371462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# MLP model ako zelimo manualno napraviti parametre\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics import accuracy_score, classification_report, confusion_matrix\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "mlp_model=MLPClassifier(hidden_layer_sizes=(100,), max_iter=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eeb9d01",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with Word2Vec and SVC\n",
    "model_pipeline = Pipeline([\n",
    "    ('word2vec', FunctionTransformer(lambda x: word2vec_features(x, word2vec_model, 100))),\n",
    "    ('classifier', mlp_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "18d4f023",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;word2vec&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001344C4B7BA0&gt;)),\n",
       "                (&#x27;classifier&#x27;, MLPClassifier())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;word2vec&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001344C4B7BA0&gt;)),\n",
       "                (&#x27;classifier&#x27;, MLPClassifier())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x000001344C4B7BA0&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">MLPClassifier</label><div class=\"sk-toggleable__content\"><pre>MLPClassifier()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('word2vec',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x000001344C4B7BA0>)),\n",
       "                ('classifier', MLPClassifier())])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36bd7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classification report:               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.64      0.44      0.52       616\n",
      "           1       0.71      0.84      0.77       984\n",
      "\n",
      "    accuracy                           0.69      1600\n",
      "   macro avg       0.67      0.64      0.65      1600\n",
      "weighted avg       0.68      0.69      0.67      1600\n",
      "\n",
      "Accuracy: 0.69\n",
      "F1 Score: 0.77\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = model_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "class_report = classification_report(y_test, predictions)\n",
    "print(f\"Classification report: {class_report}\")\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "99596e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2215    1\n",
       "2582    1\n",
       "1662    1\n",
       "3027    0\n",
       "4343    1\n",
       "       ..\n",
       "1079    0\n",
       "7979    1\n",
       "1115    0\n",
       "6093    1\n",
       "6832    1\n",
       "Name: is_humor, Length: 1600, dtype: int64"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "60863f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: 427\n",
      "Number of ones: 1173\n",
      "percentage of humoruous texts: 73.3125%\n",
      "the difference between labeled and predicted humorous: 11.65625%\n"
     ]
    }
   ],
   "source": [
    "count_zeros = (predictions == 0).sum()\n",
    "count_ones = (predictions == 1).sum()\n",
    "\n",
    "print(f\"Number of zeros: {count_zeros}\")\n",
    "print(f\"Number of ones: {count_ones}\")\n",
    "\n",
    "print(f\"percentage of humoruous texts: {count_ones*100 / len(y_test)}%\")\n",
    "print(f\"the difference between labeled and predicted humorous: {(count_ones*100 / len(y_test))-len(train_data[train_data['is_humor'] == 1]) / len(train_data) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17215e85",
   "metadata": {},
   "source": [
    "U train setu je cca 61% humoristicnih tekstova, ovdje je prema predikciji 58.31%..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.72375\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.68      0.52      0.59       307\n",
      "           1       0.74      0.85      0.79       493\n",
      "\n",
      "    accuracy                           0.72       800\n",
      "   macro avg       0.71      0.69      0.69       800\n",
      "weighted avg       0.72      0.72      0.71       800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[160 147]\n",
      " [ 74 419]]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "X_dev = dev_data['text']\n",
    "y_dev = dev_data['is_humor']\n",
    "\n",
    "y_pred = model_pipeline.predict(X_dev)\n",
    "\n",
    "# Evaluate performance\n",
    "accuracy = accuracy_score(y_dev, y_pred)\n",
    "report = classification_report(y_dev, y_pred)\n",
    "matrix = confusion_matrix(y_dev, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "348161cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulazni tekst\n",
    "input_text = \"I am so funny. Am I?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "cac4dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primijeniti istu predobradu teksta\n",
    "processed_input = preprocess_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "544d3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretvoriti tekst u vektor\n",
    "input_vector = average_word_vectors(processed_input, word2vec_model, set(word2vec_model.wv.index_to_key), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "fa7bbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input vector: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Provjeriti oblik vektora (provjeriti dimenzionalnost)\n",
    "print(\"Shape of input vector:\", input_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "38839e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input vector (2D): (1, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.54425853,  0.5649667 , -0.03600514,  0.15677033,  0.18047075,\n",
       "        -0.8998527 ,  0.16338056,  1.3484894 , -0.44480798, -0.72868586,\n",
       "        -0.01061219, -0.7751362 , -0.32850087,  0.5042129 ,  0.2550669 ,\n",
       "        -0.30292514,  0.4327028 , -0.7238214 , -0.26012614, -1.3500358 ,\n",
       "         0.31897303,  0.03051787,  0.5980095 , -0.42596254, -0.2613593 ,\n",
       "         0.00654607, -0.6209033 , -0.04399197, -0.52067703,  0.20202827,\n",
       "         0.78006434, -0.1190227 ,  0.03616504, -0.76366144,  0.036917  ,\n",
       "         0.3429152 ,  0.37522554, -0.33902064, -0.13814048, -0.8634219 ,\n",
       "         0.31757033, -0.61889595, -0.45885527, -0.1617627 ,  0.5265503 ,\n",
       "        -0.12609689, -0.5200675 , -0.30502206,  0.31923914,  0.43227735,\n",
       "         0.16344231, -0.6593407 , -0.22703467,  0.11757258, -0.32601833,\n",
       "         0.2219493 ,  0.5380323 ,  0.04997512, -0.52897257,  0.24500565,\n",
       "         0.29103133,  0.1963741 ,  0.10311357, -0.21566875, -0.48286197,\n",
       "         0.7683609 ,  0.36291817,  0.40081844, -0.68522954,  0.7968078 ,\n",
       "        -0.1610216 ,  0.36205497,  0.68014646, -0.38138947,  0.8331832 ,\n",
       "         0.04964824,  0.04667984,  0.30673558, -0.7092959 ,  0.00568559,\n",
       "        -0.33632836,  0.01441837, -0.26787642,  0.45523527, -0.29397836,\n",
       "        -0.32390139,  0.3154625 ,  0.44611445,  0.54380363, -0.08439354,\n",
       "         0.5359848 ,  0.34967756,  0.25828978, -0.09093789,  1.2360715 ,\n",
       "         0.63901895,  0.08819371, -0.44282737,  0.08593864,  0.34211317]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naparviti reshape sa 1D u 2D\n",
    "input_vector_2d = input_vector.reshape(1, -1)\n",
    "print(\"Shape of input vector (2D):\", input_vector_2d.shape)\n",
    "input_vector_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "8fa8a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ovdje dolazi do greske, treba ispraviti model i vidjeti sto je tocno krivo\n",
    "# prediction = model_pipeline.predict(input_vector_2d)\n",
    "\n",
    "# print(\"Predicted class:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
