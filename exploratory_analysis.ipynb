{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c748ad37",
   "metadata": {},
   "source": [
    "# Eksploratorn analiza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb0570",
   "metadata": {},
   "source": [
    "Problem kod dataseta u ovom zadatku je što imamo pristup samo train set-u, nemamo validacijskom i test setu. Broj redova, primjera u train setu je 8000 te sam podijelio podatke na sljedeći način: 6400 train set, 800 dev set i 800 test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "72d15a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c10d2e",
   "metadata": {},
   "source": [
    "### Puni dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4dc4ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7996</td>\n",
       "      <td>Lack of awareness of the pervasiveness of raci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7997</td>\n",
       "      <td>Why are aspirins white? Because they work sorry</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7998</td>\n",
       "      <td>Today, we Americans celebrate our independence...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7999</td>\n",
       "      <td>How to keep the flies off the bride at an Ital...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>8000</td>\n",
       "      <td>\"Each ounce of sunflower seeds gives you 37% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "0        1  TENNESSEE: We're the best state. Nobody even c...         1   \n",
       "1        2  A man inserted an advertisement in the classif...         1   \n",
       "2        3  How many men does it take to open a can of bee...         1   \n",
       "3        4  Told my mom I hit 1200 Twitter followers. She ...         1   \n",
       "4        5  Roses are dead. Love is fake. Weddings are bas...         1   \n",
       "...    ...                                                ...       ...   \n",
       "7995  7996  Lack of awareness of the pervasiveness of raci...         0   \n",
       "7996  7997    Why are aspirins white? Because they work sorry         1   \n",
       "7997  7998  Today, we Americans celebrate our independence...         1   \n",
       "7998  7999  How to keep the flies off the bride at an Ital...         1   \n",
       "7999  8000  \"Each ounce of sunflower seeds gives you 37% o...         0   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  \n",
       "0             2.42                1.0            0.20  \n",
       "1             2.50                1.0            1.10  \n",
       "2             1.95                0.0            2.40  \n",
       "3             2.11                1.0            0.00  \n",
       "4             2.78                0.0            0.10  \n",
       "...            ...                ...             ...  \n",
       "7995           NaN                NaN            0.25  \n",
       "7996          1.33                0.0            3.85  \n",
       "7997          2.55                0.0            0.00  \n",
       "7998          1.00                0.0            3.00  \n",
       "7999           NaN                NaN            0.00  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3f3a7",
   "metadata": {},
   "source": [
    "Značenje stupaca:\n",
    "\n",
    "- id - Ovo je identifikacijski broj za svaku recenicu. Može se koristiti za jedinstveno identificiranje svake stavke u skupu podataka.\n",
    "- text - Ovaj stupac sadrži rečenice koje je potrebno analizirati.\n",
    "- is_humor - binarna oznaka (0 ili 1) koja označava ima li rečenica humor ili ne. Ako je vrijednost 1, rečenica je označena kao humoristična, ako je 0, rečenica nije .\n",
    "- humor_rating - Numerička ocjena (1-5) koja predstavlja subjektivnu percepciju anotatora o tome koliko je rečenica smiješna. Anotatori su ocijenili smiješnost rečenice na skali od 1 do 5.\n",
    "- humor_controversy - Binarna oznaka (0 ili 1) koja označava ima li kontroverzu humora u rečenici. Ako je vrijednost 1, to znači da je ocjena humora za tu rečenicu kontroverzna.\n",
    "- offense_rating - Numerička ocjena (1-5) koja predstavlja subjektivnu percepciju anotatora o tome koliko je rečenica uvredljiva. Anotatori su ocijenili razinu uvredljivosti rečenice na skali od 1 do 5. Ovdje se također razmatra da nedavanje ocjene jednako 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4153fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id     is_humor  humor_rating  humor_controversy  \\\n",
      "count  8000.00000  8000.000000   4932.000000        4932.000000   \n",
      "mean   4000.50000     0.616500      2.260525           0.499797   \n",
      "std    2309.54541     0.486269      0.566974           0.500051   \n",
      "min       1.00000     0.000000      0.100000           0.000000   \n",
      "25%    2000.75000     0.000000      1.890000           0.000000   \n",
      "50%    4000.50000     1.000000      2.280000           0.000000   \n",
      "75%    6000.25000     1.000000      2.650000           1.000000   \n",
      "max    8000.00000     1.000000      4.000000           1.000000   \n",
      "\n",
      "       offense_rating  \n",
      "count     8000.000000  \n",
      "mean         0.585325  \n",
      "std          0.979955  \n",
      "min          0.000000  \n",
      "25%          0.000000  \n",
      "50%          0.100000  \n",
      "75%          0.700000  \n",
      "max          4.850000  \n",
      "\n",
      "\n",
      "Broj humoristicnih tekstova: 4932\n",
      "Broj ne humoristicnih: 3068\n",
      "Broj NaN zapisa: 0\n",
      "Broj NaN zapisa: 3068\n",
      "Broj NaN zapisa: 3068\n",
      "Broj NaN zapisa: 0\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())\n",
    "print()\n",
    "print()\n",
    "print(f\"Broj humoristicnih tekstova: {len(data[data['is_humor'] == 1])}\")\n",
    "print(f\"Broj ne humoristicnih: {len(data[data['is_humor'] == 0])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['is_humor'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['humor_rating'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['humor_controversy'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['offense_rating'].isna()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c3861331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj redaka bez NaN vrijednosti u 'text' stupcu: 8000\n"
     ]
    }
   ],
   "source": [
    "# Provjerava ima li unos u svakom redu za 'text' stupac\n",
    "text_column_not_null = data['text'].dropna()\n",
    "\n",
    "# Ispisuje duljinu rezultirajućeg DataFrame-a\n",
    "print(f\"Broj redaka bez NaN vrijednosti u 'text' stupcu: {len(text_column_not_null)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8d34ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udio kontroverznosti humora: 30.81%\n"
     ]
    }
   ],
   "source": [
    "# Udio kontroverznosti humora\n",
    "controversial_count = data['humor_controversy'].sum()\n",
    "total_samples = len(data)\n",
    "\n",
    "print(f\"Udio kontroverznosti humora: {controversial_count / total_samples * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "39757bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentence_length\n",
      "0  TENNESSEE: We're the best state. Nobody even c...               17\n",
      "1  A man inserted an advertisement in the classif...               32\n",
      "2  How many men does it take to open a can of bee...               26\n",
      "3  Told my mom I hit 1200 Twitter followers. She ...               26\n",
      "4  Roses are dead. Love is fake. Weddings are bas...               12\n",
      "sentence_length    20.889375\n",
      "dtype: float64\n",
      "is_humor\n",
      "0    21.932855\n",
      "1    20.240268\n",
      "Name: sentence_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analiza duljine rečenica\n",
    "data['sentence_length'] = data['text'].apply(lambda x: len(x.split()))\n",
    "print(data[['text', 'sentence_length']].head())\n",
    "print(data[['sentence_length']].mean())\n",
    "print(data.groupby('is_humor')['sentence_length'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72dbc6",
   "metadata": {},
   "source": [
    "Training set ne sadrži neispravne primjere. Gdje su vrijednosti is_humor == 0, tj. za tekstove koji nisu humoristični nema vrijednosti humor_rating\ti humor_controversy jer to za njih niti nije moguće izračunati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40bbb0",
   "metadata": {},
   "source": [
    "### Podjela dataset-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "06ec1279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of train set: 6400\n",
      "Size of dev set: 800\n",
      "Size of test set: 800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "# Assuming you have a dataframe 'data' with features and labels\n",
    "# X contains your features, y contains your labels\n",
    "\n",
    "# Create an instance of StratifiedShuffleSplit for splitting into train and temp sets\n",
    "stratified_splitter_train_temp = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "\n",
    "# Use the splitter to generate indices for train and temp sets\n",
    "for train_index, temp_index in stratified_splitter_train_temp.split(data, data['is_humor']):\n",
    "    train_data, temp_data = data.iloc[train_index], data.iloc[temp_index]\n",
    "\n",
    "# Create an instance of StratifiedShuffleSplit for further splitting temp into dev and test sets\n",
    "stratified_splitter_temp_dev_test = StratifiedShuffleSplit(n_splits=1, test_size=0.5, random_state=42)\n",
    "\n",
    "# Use the splitter to generate indices for dev and test sets\n",
    "for dev_index, test_index in stratified_splitter_temp_dev_test.split(temp_data, temp_data['is_humor']):\n",
    "    dev_data, test_data = temp_data.iloc[dev_index], temp_data.iloc[test_index]\n",
    "\n",
    "# Print the sizes of the obtained sets\n",
    "print(f\"Size of train set: {len(train_data)}\")\n",
    "print(f\"Size of dev set: {len(dev_data)}\")\n",
    "print(f\"Size of test set: {len(test_data)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "578e77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spremi train set u CSV file\n",
    "train_data.to_csv('data/train.csv', index=False)\n",
    "\n",
    "# Spremi dev set u CSV file\n",
    "dev_data.to_csv('data/dev.csv', index=False)\n",
    "\n",
    "# Spremi test set u CSV file\n",
    "test_data.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f408b0",
   "metadata": {},
   "source": [
    "### Odnos humorističnih i nehumorističnih tekstova u train i dev setu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "be9b16fe",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2023-11-15T16:31:34.315146Z",
     "start_time": "2023-11-15T16:31:34.223500Z"
    }
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mNameError\u001B[0m                                 Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[1], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m \u001B[43mtrain_data\u001B[49m\n",
      "\u001B[0;31mNameError\u001B[0m: name 'train_data' is not defined"
     ]
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "ec291252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postotak humorističnih tekstova u train setu: 61.66%\n",
      "Postotak nehumorističnih tekstova u train setu: 38.34%\n"
     ]
    }
   ],
   "source": [
    "# Broj humorističnih tekstova u train setu\n",
    "humor_percent = len(train_data[train_data['is_humor'] == 1]) / len(train_data) * 100\n",
    "\n",
    "# Broj nehumorističnih tekstova u train setu\n",
    "non_humor_percent = len(train_data[train_data['is_humor'] == 0]) / len(train_data) * 100\n",
    "\n",
    "# Ispis rezultata s dvije decimale\n",
    "print(f\"Postotak humorističnih tekstova u train setu: {humor_percent:.2f}%\")\n",
    "print(f\"Postotak nehumorističnih tekstova u train setu: {non_humor_percent:.2f}%\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "dcdfa08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1864</th>\n",
       "      <td>1865</td>\n",
       "      <td>Me: What are my chances doc? Doctor: The surge...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.40</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>32</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7235</th>\n",
       "      <td>7236</td>\n",
       "      <td>Why do fish live in salt water? Because pepper...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2687</th>\n",
       "      <td>2688</td>\n",
       "      <td>Family, we appreciate your patience. Due to fu...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1454</th>\n",
       "      <td>1455</td>\n",
       "      <td>John F. Kennedy's brain has been missing for 5...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.27</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.55</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7830</th>\n",
       "      <td>7831</td>\n",
       "      <td>\"Blueberry juice boosts memory\"</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1803</th>\n",
       "      <td>1804</td>\n",
       "      <td>On a daily basis some young gay guys get HIV t...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>51</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4749</th>\n",
       "      <td>4750</td>\n",
       "      <td>just had a redbull, feelin' good, energetic, m...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2140</th>\n",
       "      <td>2141</td>\n",
       "      <td>We would like to remind you that registration ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.20</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4140</th>\n",
       "      <td>4141</td>\n",
       "      <td>I'm a big fan of people being exactly who they...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>750</td>\n",
       "      <td>Everybody's a gangster until they get punched ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.89</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "1864  1865  Me: What are my chances doc? Doctor: The surge...         1   \n",
       "7235  7236  Why do fish live in salt water? Because pepper...         1   \n",
       "2687  2688  Family, we appreciate your patience. Due to fu...         0   \n",
       "1454  1455  John F. Kennedy's brain has been missing for 5...         1   \n",
       "7830  7831                    \"Blueberry juice boosts memory\"         0   \n",
       "...    ...                                                ...       ...   \n",
       "1803  1804  On a daily basis some young gay guys get HIV t...         0   \n",
       "4749  4750  just had a redbull, feelin' good, energetic, m...         0   \n",
       "2140  2141  We would like to remind you that registration ...         0   \n",
       "4140  4141  I'm a big fan of people being exactly who they...         0   \n",
       "749    750  Everybody's a gangster until they get punched ...         1   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  sentence_length  \n",
       "1864          2.40                1.0            0.00               32  \n",
       "7235          2.60                1.0            0.00               13  \n",
       "2687           NaN                NaN            0.00               46  \n",
       "1454          1.27                0.0            1.55               10  \n",
       "7830           NaN                NaN            0.05                4  \n",
       "...            ...                ...             ...              ...  \n",
       "1803           NaN                NaN            0.00               51  \n",
       "4749           NaN                NaN            0.00               22  \n",
       "2140           NaN                NaN            0.20               22  \n",
       "4140           NaN                NaN            0.00               16  \n",
       "749           2.89                1.0            0.25               19  \n",
       "\n",
       "[800 rows x 7 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "37a925dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postotak humorističnih tekstova u dev setu: 61.62%\n",
      "Postotak nehumorističnih tekstova u dev setu: 38.38%\n"
     ]
    }
   ],
   "source": [
    "# Broj humorističnih tekstova u dev setu\n",
    "humor_percent = len(dev_data[dev_data['is_humor'] == 1]) / len(dev_data) * 100\n",
    "\n",
    "# Broj nehumorističnih tekstova u dev setu\n",
    "non_humor_percent = len(dev_data[dev_data['is_humor'] == 0]) / len(dev_data) * 100\n",
    "\n",
    "# Ispis rezultata s dvije decimale\n",
    "print(f\"Postotak humorističnih tekstova u dev setu: {humor_percent:.2f}%\")\n",
    "print(f\"Postotak nehumorističnih tekstova u dev setu: {non_humor_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46e584",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b09d18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\josip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\josip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\josip\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a351503d",
   "metadata": {},
   "source": [
    "#### Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d844ec7a",
   "metadata": {},
   "source": [
    "In order to use Word2Vec, you need to pre-process the data. It's very simple: you just need to split sentences to words (tokenization), bring the words to their basic form (lemmatization), and remove some very common words like articles or prepositions (stop-word removal). I'm using RegexpTokenizer, WordNetLemmatizer and NLTK stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6fe786d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "23efeb6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a040fac0",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "f1fb7046",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['processed_text'], \n",
    "    data['is_humor'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bd774026",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model training\n",
    "word2vec_model = Word2Vec(sentences=X_train.apply(word_tokenize), vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "73b71216",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average word vectors for a sentence\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            n_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    if n_words:\n",
    "        feature_vector = np.divide(feature_vector, n_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "718f06f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data to Word2Vec features\n",
    "def word2vec_features(data, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    return np.vstack([average_word_vectors(tokens, model, vocabulary, num_features) for tokens in data.apply(word_tokenize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c6371462",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC model ako zelimo manualno napraviti parametre\n",
    "# svc_model = SVC(class_weight='balanced',C=9,gamma='scale')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0eeb9d01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "najbolji koeficijent C je : 4\n",
      "najbolji koeficijent gamma je : 4\n"
     ]
    }
   ],
   "source": [
    "# Create a pipeline with Word2Vec and SVC\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import f1_score\n",
    "svc_c=[0.25,0.5,1,2,4]\n",
    "svc_gamma=[0.25,0.5,1,2,4]\n",
    "fbest=0\n",
    "cbest=0\n",
    "gammabest=0\n",
    "X_dev = dev_data['text']\n",
    "y_dev = dev_data['is_humor']\n",
    "\n",
    "for i in svc_c:\n",
    "  for j in svc_gamma:\n",
    "    svc_model=SVC(class_weight='balanced',C=i,gamma=j)\n",
    "    model_pipeline = Pipeline([\n",
    "    ('word2vec', FunctionTransformer(lambda x: word2vec_features(x, word2vec_model, 100))),\n",
    "    ('svc', svc_model)\n",
    "    ])\n",
    "    model_pipeline.fit(X_train, y_train)\n",
    "    y_pred = model_pipeline.predict(X_dev)\n",
    "    weighted_f1 = f1_score(y_dev, y_pred, average='weighted')\n",
    "    if weighted_f1>fbest:\n",
    "      fbest=weighted_f1\n",
    "      cbest=i\n",
    "      gammabest=j\n",
    "\n",
    "print(f\"najbolji koeficijent C je : {cbest}\")\n",
    "print(f\"najbolji koeficijent gamma je : {gammabest}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Nakon prolaženja kroz sve moguće kombinacije, ispostavlja se da su najbolji koeficijenti C:4 i gamma:4"
   ],
   "id": "de7e796f452d6f9d"
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "36bd7f0f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.695\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           0       0.59      0.69      0.63       307\n",
      "           1       0.78      0.70      0.74       493\n",
      "\n",
      "    accuracy                           0.69       800\n",
      "   macro avg       0.69      0.69      0.69       800\n",
      "weighted avg       0.71      0.69      0.70       800\n",
      "\n",
      "Confusion Matrix:\n",
      " [[212  95]\n",
      " [149 344]]\n",
      "F1 Score: 0.74\n"
     ]
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svc_model=SVC(class_weight='balanced',C=cbest,gamma=gammabest)\n",
    "model_pipeline = Pipeline([\n",
    "    ('word2vec', FunctionTransformer(lambda x: word2vec_features(x, word2vec_model, 100))),\n",
    "    ('svc', svc_model)\n",
    "    ])\n",
    "\n",
    "\n",
    "model_pipeline.fit(X_train, y_train)\n",
    "y_pred = model_pipeline.predict(X_dev)\n",
    "accuracy = accuracy_score(y_dev, y_pred)\n",
    "f1 = f1_score(y_dev, y_pred)\n",
    "report = classification_report(y_dev, y_pred)\n",
    "matrix = confusion_matrix(y_dev, y_pred)\n",
    "\n",
    "print(f\"Accuracy: {accuracy}\")\n",
    "print(\"Classification Report:\\n\", report)\n",
    "print(\"Confusion Matrix:\\n\", matrix)\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "99596e96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2215    1\n",
       "2582    1\n",
       "1662    1\n",
       "3027    0\n",
       "4343    1\n",
       "       ..\n",
       "1079    0\n",
       "7979    1\n",
       "1115    0\n",
       "6093    1\n",
       "6832    1\n",
       "Name: is_humor, Length: 1600, dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "60863f53",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: 361\n",
      "Number of ones: 439\n",
      "percentage of humoruous texts: 27.4375%\n",
      "the difference between labeled and predicted humorous: -34.21875%\n"
     ]
    }
   ],
   "source": [
    "count_zeros = (y_pred == 0).sum()\n",
    "count_ones = (y_pred == 1).sum()\n",
    "\n",
    "print(f\"Number of zeros: {count_zeros}\")\n",
    "print(f\"Number of ones: {count_ones}\")\n",
    "\n",
    "print(f\"percentage of humoruous texts: {count_ones*100 / len(y_test)}%\")\n",
    "print(f\"the difference between labeled and predicted humorous: {(count_ones*100 / len(y_test))-len(train_data[train_data['is_humor'] == 1]) / len(train_data) * 100}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17215e85",
   "metadata": {},
   "source": [
    "U train setu je cca 61% humoristicnih tekstova, ovdje je prema predikciji 27.43%..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_dev = dev_data['text']\n",
    "y_dev = dev_data['is_humor']"
   ],
   "id": "a552a569a9e85b83"
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "348161cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulazni tekst\n",
    "input_text = \"I am so funny. Am I?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "cac4dad0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primijeniti istu predobradu teksta\n",
    "processed_input = preprocess_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "544d3e93",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretvoriti tekst u vektor\n",
    "input_vector = average_word_vectors(processed_input, word2vec_model, set(word2vec_model.wv.index_to_key), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "fa7bbc8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input vector: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Provjeriti oblik vektora (provjeriti dimenzionalnost)\n",
    "print(\"Shape of input vector:\", input_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "38839e6b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input vector (2D): (1, 100)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[-0.5024133 ,  0.504933  , -0.07783732,  0.35330155,  0.1552279 ,\n",
       "        -1.0222636 ,  0.30443498,  1.3806643 , -0.61616415, -0.59900904,\n",
       "         0.02905955, -0.6353491 , -0.4189774 ,  0.4878517 ,  0.21311246,\n",
       "        -0.27212664,  0.41845775, -0.6468848 , -0.2138551 , -1.3454555 ,\n",
       "         0.38248172,  0.12233138,  0.591286  , -0.34985256, -0.1877069 ,\n",
       "        -0.20238562, -0.66752607, -0.0459352 , -0.43058452,  0.20604177,\n",
       "         0.8307226 , -0.2583981 ,  0.10794821, -0.7405246 ,  0.18740238,\n",
       "         0.33053324,  0.2248956 , -0.1434512 , -0.25625452, -0.85871667,\n",
       "         0.28272918, -0.6718759 , -0.35356963, -0.21081306,  0.45954466,\n",
       "        -0.15444365, -0.6729226 , -0.19601186,  0.34043658,  0.37967452,\n",
       "         0.14469112, -0.57948637, -0.26184067,  0.18386413, -0.3364242 ,\n",
       "         0.15065046,  0.49665654,  0.09538326, -0.7039183 ,  0.16207944,\n",
       "         0.31667033,  0.27700377,  0.18367863, -0.17379133, -0.4677265 ,\n",
       "         0.8068237 ,  0.4077135 ,  0.39553174, -0.6678675 ,  0.7167604 ,\n",
       "        -0.24778016,  0.33300114,  0.6902556 , -0.3417975 ,  0.72291845,\n",
       "        -0.07325244,  0.14490217,  0.2374715 , -0.6494468 , -0.07401326,\n",
       "        -0.35217988,  0.03445877, -0.2288111 ,  0.42012033, -0.2808344 ,\n",
       "        -0.40224275,  0.3012536 ,  0.40957847,  0.62555546, -0.01775179,\n",
       "         0.49934807,  0.29063118,  0.305228  , -0.04447808,  1.134261  ,\n",
       "         0.72880703,  0.10272485, -0.41339183,  0.0732656 ,  0.39308593]],\n",
       "      dtype=float32)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Naparviti reshape sa 1D u 2D\n",
    "input_vector_2d = input_vector.reshape(1, -1)\n",
    "print(\"Shape of input vector (2D):\", input_vector_2d.shape)\n",
    "input_vector_2d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8fa8a609",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ovdje dolazi do greske, treba ispraviti model i vidjeti sto je tocno krivo\n",
    "# prediction = model_pipeline.predict(input_vector_2d)\n",
    "\n",
    "# print(\"Predicted class:\", prediction)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
