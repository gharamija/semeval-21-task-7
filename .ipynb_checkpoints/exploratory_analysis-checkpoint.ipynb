{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c748ad37",
   "metadata": {},
   "source": [
    "# Eksploratorn analiza"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ebfb0570",
   "metadata": {},
   "source": [
    "Problem kod dataseta u ovom zadatku je što imamo pristup samo train set-u, nemamo validacijskom i test setu. Broj redova, primjera u train setu je 8000 te sam podijelio podatke na sljedeći način: 6400 train set, 800 dev set i 800 test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "72d15a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7c10d2e",
   "metadata": {},
   "source": [
    "### Puni dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4dc4ff37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7996</td>\n",
       "      <td>Lack of awareness of the pervasiveness of raci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7997</td>\n",
       "      <td>Why are aspirins white? Because they work sorry</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7998</td>\n",
       "      <td>Today, we Americans celebrate our independence...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7999</td>\n",
       "      <td>How to keep the flies off the bride at an Ital...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>8000</td>\n",
       "      <td>\"Each ounce of sunflower seeds gives you 37% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "0        1  TENNESSEE: We're the best state. Nobody even c...         1   \n",
       "1        2  A man inserted an advertisement in the classif...         1   \n",
       "2        3  How many men does it take to open a can of bee...         1   \n",
       "3        4  Told my mom I hit 1200 Twitter followers. She ...         1   \n",
       "4        5  Roses are dead. Love is fake. Weddings are bas...         1   \n",
       "...    ...                                                ...       ...   \n",
       "7995  7996  Lack of awareness of the pervasiveness of raci...         0   \n",
       "7996  7997    Why are aspirins white? Because they work sorry         1   \n",
       "7997  7998  Today, we Americans celebrate our independence...         1   \n",
       "7998  7999  How to keep the flies off the bride at an Ital...         1   \n",
       "7999  8000  \"Each ounce of sunflower seeds gives you 37% o...         0   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  \n",
       "0             2.42                1.0            0.20  \n",
       "1             2.50                1.0            1.10  \n",
       "2             1.95                0.0            2.40  \n",
       "3             2.11                1.0            0.00  \n",
       "4             2.78                0.0            0.10  \n",
       "...            ...                ...             ...  \n",
       "7995           NaN                NaN            0.25  \n",
       "7996          1.33                0.0            3.85  \n",
       "7997          2.55                0.0            0.00  \n",
       "7998          1.00                0.0            3.00  \n",
       "7999           NaN                NaN            0.00  \n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('data/dataset.csv')\n",
    "data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d3f3a7",
   "metadata": {},
   "source": [
    "Značenje stupaca:\n",
    "\n",
    "    - id - Ovo je identifikacijski broj za svaku recenicu. Može se koristiti za jedinstveno identificiranje svake stavke u skupu podataka.\n",
    "    - text - Ovaj stupac sadrži rečenice koje je potrebno analizirati.\n",
    "    - is_humor - inarna oznaka (0 ili 1) koja označava ima li rečenica humor ili ne. Ako je vrijednost 1, rečenica je označena kao humoristična, ako je 0, rečenica nije .\n",
    "    - humor_rating - Numerička ocjena (1-5) koja predstavlja subjektivnu percepciju anotatora o tome koliko je rečenica smiješna. Anotatori su ocijenili smiješnost rečenice na skali od 1 do 5.\n",
    "    - humor_controversy - Binarna oznaka (0 ili 1) koja označava ima li kontroverzu humora u rečenici. Ako je vrijednost 1, to znači da je ocjena humora za tu rečenicu kontroverzna.\n",
    "    - offense_rating - Numerička ocjena (1-5) koja predstavlja subjektivnu percepciju anotatora o tome koliko je rečenica uvredljiva. Anotatori su ocijenili razinu uvredljivosti rečenice na skali od 1 do 5. Ovdje se također razmatra da nedavanje ocjene jednako 0."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4153fe1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               id     is_humor  humor_rating  humor_controversy  \\\n",
      "count  8000.00000  8000.000000   4932.000000        4932.000000   \n",
      "mean   4000.50000     0.616500      2.260525           0.499797   \n",
      "std    2309.54541     0.486269      0.566974           0.500051   \n",
      "min       1.00000     0.000000      0.100000           0.000000   \n",
      "25%    2000.75000     0.000000      1.890000           0.000000   \n",
      "50%    4000.50000     1.000000      2.280000           0.000000   \n",
      "75%    6000.25000     1.000000      2.650000           1.000000   \n",
      "max    8000.00000     1.000000      4.000000           1.000000   \n",
      "\n",
      "       offense_rating  \n",
      "count     8000.000000  \n",
      "mean         0.585325  \n",
      "std          0.979955  \n",
      "min          0.000000  \n",
      "25%          0.000000  \n",
      "50%          0.100000  \n",
      "75%          0.700000  \n",
      "max          4.850000  \n",
      "\n",
      "\n",
      "Broj humoristicnih tekstova: 4932\n",
      "Broj ne humoristicnih: 3068\n",
      "Broj NaN zapisa: 0\n",
      "Broj NaN zapisa: 3068\n",
      "Broj NaN zapisa: 3068\n",
      "Broj NaN zapisa: 0\n"
     ]
    }
   ],
   "source": [
    "print(data.describe())\n",
    "print()\n",
    "print()\n",
    "print(f\"Broj humoristicnih tekstova: {len(data[data['is_humor'] == 1])}\")\n",
    "print(f\"Broj ne humoristicnih: {len(data[data['is_humor'] == 0])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['is_humor'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['humor_rating'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['humor_controversy'].isna()])}\")\n",
    "print(f\"Broj NaN zapisa: {len(data[data['offense_rating'].isna()])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c3861331",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Broj redaka bez NaN vrijednosti u 'text' stupcu: 8000\n"
     ]
    }
   ],
   "source": [
    "# Provjerava ima li unos u svakom redu za 'text' stupac\n",
    "text_column_not_null = data['text'].dropna()\n",
    "\n",
    "# Ispisuje duljinu rezultirajućeg DataFrame-a\n",
    "print(f\"Broj redaka bez NaN vrijednosti u 'text' stupcu: {len(text_column_not_null)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d34ab21",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Udio kontroverznosti humora: 30.81%\n"
     ]
    }
   ],
   "source": [
    "# Udio kontroverznosti humora\n",
    "controversial_count = data['humor_controversy'].sum()\n",
    "total_samples = len(data)\n",
    "\n",
    "print(f\"Udio kontroverznosti humora: {controversial_count / total_samples * 100:.2f}%\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39757bd9",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                                text  sentence_length\n",
      "0  TENNESSEE: We're the best state. Nobody even c...               17\n",
      "1  A man inserted an advertisement in the classif...               32\n",
      "2  How many men does it take to open a can of bee...               26\n",
      "3  Told my mom I hit 1200 Twitter followers. She ...               26\n",
      "4  Roses are dead. Love is fake. Weddings are bas...               12\n",
      "sentence_length    20.889375\n",
      "dtype: float64\n",
      "is_humor\n",
      "0    21.932855\n",
      "1    20.240268\n",
      "Name: sentence_length, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# Analiza duljine rečenica\n",
    "data['sentence_length'] = data['text'].apply(lambda x: len(x.split()))\n",
    "print(data[['text', 'sentence_length']].head())\n",
    "print(data[['sentence_length']].mean())\n",
    "print(data.groupby('is_humor')['sentence_length'].mean())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db72dbc6",
   "metadata": {},
   "source": [
    "Training set ne sadrži neispravne primjere. Gdje su vrijednosti is_humor == 0, tj. za tekstove koji nisu humoristični nema vrijednosti humor_rating\ti humor_controversy jer to za njih niti nije moguće izračunati."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a40bbb0",
   "metadata": {},
   "source": [
    "### Podjela dataset-a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "06ec1279",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Veličina train seta: 6400\n",
      "Veličina dev seta: 800\n",
      "Veličina test seta: 800\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Podijeli train set na train i privremeni set (ostatak)\n",
    "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=42)\n",
    "\n",
    "# Podijeli privremeni set na dev i test set\n",
    "dev_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Ispisuje veličine dobivenih setova\n",
    "print(f\"Veličina train seta: {len(train_data)}\")\n",
    "print(f\"Veličina dev seta: {len(dev_data)}\")\n",
    "print(f\"Veličina test seta: {len(test_data)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "578e77e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Spremi train set u CSV file\n",
    "train_data.to_csv('data/train.csv', index=False)\n",
    "\n",
    "# Spremi dev set u CSV file\n",
    "dev_data.to_csv('data/dev.csv', index=False)\n",
    "\n",
    "# Spremi test set u CSV file\n",
    "test_data.to_csv('data/test.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12f408b0",
   "metadata": {},
   "source": [
    "### Odnos humorističnih i nehumorističnih tekstova u train i dev setu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "be9b16fe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1467</th>\n",
       "      <td>1468</td>\n",
       "      <td>customer: i'd like to return this boomerang me...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.30</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5768</th>\n",
       "      <td>5769</td>\n",
       "      <td>Keep your ears ready for next week, when The A...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.50</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5714</th>\n",
       "      <td>5715</td>\n",
       "      <td>[2 am] *5 year old sneaks into my room* 5: (wh...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>36</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1578</th>\n",
       "      <td>1579</td>\n",
       "      <td>Sex and food activate the same parts of the br...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6958</th>\n",
       "      <td>6959</td>\n",
       "      <td>Gay or straight, No state should legally recog...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.30</td>\n",
       "      <td>18</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5226</th>\n",
       "      <td>5227</td>\n",
       "      <td>What is a pirates favorite letter? P. Because ...</td>\n",
       "      <td>1</td>\n",
       "      <td>3.00</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>13</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5390</th>\n",
       "      <td>5391</td>\n",
       "      <td>My parents just said they want another child. ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.60</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.15</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>860</th>\n",
       "      <td>861</td>\n",
       "      <td>Don't depend too much on anyone in this world ...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7603</th>\n",
       "      <td>7604</td>\n",
       "      <td>When my toddler gets upset, he does this stomp...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7270</th>\n",
       "      <td>7271</td>\n",
       "      <td>An 89 is just a 69 with a fat chick.</td>\n",
       "      <td>1</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.25</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>6400 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "1467  1468  customer: i'd like to return this boomerang me...         1   \n",
       "5768  5769  Keep your ears ready for next week, when The A...         0   \n",
       "5714  5715  [2 am] *5 year old sneaks into my room* 5: (wh...         1   \n",
       "1578  1579  Sex and food activate the same parts of the br...         0   \n",
       "6958  6959  Gay or straight, No state should legally recog...         1   \n",
       "...    ...                                                ...       ...   \n",
       "5226  5227  What is a pirates favorite letter? P. Because ...         1   \n",
       "5390  5391  My parents just said they want another child. ...         1   \n",
       "860    861  Don't depend too much on anyone in this world ...         0   \n",
       "7603  7604  When my toddler gets upset, he does this stomp...         1   \n",
       "7270  7271               An 89 is just a 69 with a fat chick.         1   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  sentence_length  \n",
       "1467          2.30                1.0            0.00               14  \n",
       "5768           NaN                NaN            0.50               18  \n",
       "5714          3.00                0.0            0.00               36  \n",
       "1578           NaN                NaN            0.10               10  \n",
       "6958          2.25                1.0            0.30               18  \n",
       "...            ...                ...             ...              ...  \n",
       "5226          3.00                1.0            0.15               13  \n",
       "5390          2.60                1.0            0.15               21  \n",
       "860            NaN                NaN            0.00               21  \n",
       "7603          2.55                0.0            0.10               33  \n",
       "7270          2.05                0.0            2.25               10  \n",
       "\n",
       "[6400 rows x 7 columns]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec291252",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postotak humorističnih tekstova u train setu: 61.69%\n",
      "Postotak nehumorističnih tekstova u train setu: 38.31%\n"
     ]
    }
   ],
   "source": [
    "# Broj humorističnih tekstova u train setu\n",
    "humor_percent = len(train_data[train_data['is_humor'] == 1]) / len(train_data) * 100\n",
    "\n",
    "# Broj nehumorističnih tekstova u train setu\n",
    "non_humor_percent = len(train_data[train_data['is_humor'] == 0]) / len(train_data) * 100\n",
    "\n",
    "# Ispis rezultata s dvije decimale\n",
    "print(f\"Postotak humorističnih tekstova u train setu: {humor_percent:.2f}%\")\n",
    "print(f\"Postotak nehumorističnih tekstova u train setu: {non_humor_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "dcdfa08a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>sentence_length</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1606</th>\n",
       "      <td>1607</td>\n",
       "      <td>Weird situation based questions are great open...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2094</th>\n",
       "      <td>2095</td>\n",
       "      <td>Joseph confronts Mary... Joseph: \"Mary, I've h...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.80</td>\n",
       "      <td>1.0</td>\n",
       "      <td>2.05</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1034</th>\n",
       "      <td>1035</td>\n",
       "      <td>Why do the French like to eat snails so much? ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.79</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.25</td>\n",
       "      <td>15</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7463</th>\n",
       "      <td>7464</td>\n",
       "      <td>\"When we're told not to touch something we usu...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5363</th>\n",
       "      <td>5364</td>\n",
       "      <td>Did you hear about the Native American who dra...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.80</td>\n",
       "      <td>19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5551</th>\n",
       "      <td>5552</td>\n",
       "      <td>[gym] Personal Trainer: (looking at my workout...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.22</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6334</th>\n",
       "      <td>6335</td>\n",
       "      <td>I just got a ticket for driving while wearing ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.25</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5103</th>\n",
       "      <td>5104</td>\n",
       "      <td>If I learned anything from Forest Gump it's th...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.35</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2264</th>\n",
       "      <td>2265</td>\n",
       "      <td>\"Gangsta's Paradise\" has no profanity in it be...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3660</th>\n",
       "      <td>3661</td>\n",
       "      <td>\"You've gotta get up and try.\" - P!nk.</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>800 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "1606  1607  Weird situation based questions are great open...         1   \n",
       "2094  2095  Joseph confronts Mary... Joseph: \"Mary, I've h...         1   \n",
       "1034  1035  Why do the French like to eat snails so much? ...         1   \n",
       "7463  7464  \"When we're told not to touch something we usu...         0   \n",
       "5363  5364  Did you hear about the Native American who dra...         1   \n",
       "...    ...                                                ...       ...   \n",
       "5551  5552  [gym] Personal Trainer: (looking at my workout...         1   \n",
       "6334  6335  I just got a ticket for driving while wearing ...         1   \n",
       "5103  5104  If I learned anything from Forest Gump it's th...         1   \n",
       "2264  2265  \"Gangsta's Paradise\" has no profanity in it be...         0   \n",
       "3660  3661             \"You've gotta get up and try.\" - P!nk.         0   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  sentence_length  \n",
       "1606          1.80                1.0            0.10               33  \n",
       "2094          2.80                1.0            2.05               28  \n",
       "1034          2.79                0.0            0.25               15  \n",
       "7463           NaN                NaN            0.00               24  \n",
       "5363          1.65                0.0            1.80               19  \n",
       "...            ...                ...             ...              ...  \n",
       "5551          2.22                0.0            0.00               26  \n",
       "6334          2.25                1.0            0.10               28  \n",
       "5103          2.00                0.0            3.35               16  \n",
       "2264           NaN                NaN            0.00               21  \n",
       "3660           NaN                NaN            0.00                8  \n",
       "\n",
       "[800 rows x 7 columns]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "37a925dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Postotak humorističnih tekstova u dev setu: 63.38%\n",
      "Postotak nehumorističnih tekstova u dev setu: 36.62%\n"
     ]
    }
   ],
   "source": [
    "# Broj humorističnih tekstova u dev setu\n",
    "humor_percent = len(dev_data[dev_data['is_humor'] == 1]) / len(dev_data) * 100\n",
    "\n",
    "# Broj nehumorističnih tekstova u dev setu\n",
    "non_humor_percent = len(dev_data[dev_data['is_humor'] == 0]) / len(dev_data) * 100\n",
    "\n",
    "# Ispis rezultata s dvije decimale\n",
    "print(f\"Postotak humorističnih tekstova u dev setu: {humor_percent:.2f}%\")\n",
    "print(f\"Postotak nehumorističnih tekstova u dev setu: {non_humor_percent:.2f}%\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c46e584",
   "metadata": {},
   "source": [
    "## Baseline model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "b09d18ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/gasparko/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package punkt to /Users/gasparko/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     /Users/gasparko/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "\n",
    "import nltk\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk import WordNetLemmatizer\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "import numpy as np\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0faa92b0",
   "metadata": {},
   "source": [
    "#### Pre-process the data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "756d754b",
   "metadata": {},
   "source": [
    "In order to use Word2Vec, you need to pre-process the data. It's very simple: you just need to split sentences to words (tokenization), bring the words to their basic form (lemmatization), and remove some very common words like articles or prepositions (stop-word removal). I'm using RegexpTokenizer, WordNetLemmatizer and NLTK stop word list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "73a572de",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer = WordNetLemmatizer()\n",
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "5c35ce02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(text):\n",
    "    tokens = word_tokenize(text)\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens if token.lower() not in stop_words]\n",
    "    return ' '.join(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "482adff7",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['processed_text'] = data['text'].apply(preprocess_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "a8a1b170",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>text</th>\n",
       "      <th>is_humor</th>\n",
       "      <th>humor_rating</th>\n",
       "      <th>humor_controversy</th>\n",
       "      <th>offense_rating</th>\n",
       "      <th>sentence_length</th>\n",
       "      <th>processed_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>TENNESSEE: We're the best state. Nobody even c...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.42</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>17</td>\n",
       "      <td>TENNESSEE : 're best state . Nobody even come ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>A man inserted an advertisement in the classif...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.50</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.10</td>\n",
       "      <td>32</td>\n",
       "      <td>man inserted advertisement classified `` Wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>How many men does it take to open a can of bee...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.95</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.40</td>\n",
       "      <td>26</td>\n",
       "      <td>many men take open beer ? None . open time bri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Told my mom I hit 1200 Twitter followers. She ...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.11</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>26</td>\n",
       "      <td>Told mom hit 1200 Twitter follower . pointed b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>Roses are dead. Love is fake. Weddings are bas...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.78</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.10</td>\n",
       "      <td>12</td>\n",
       "      <td>Roses dead . Love fake . Weddings basically fu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>7996</td>\n",
       "      <td>Lack of awareness of the pervasiveness of raci...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.25</td>\n",
       "      <td>27</td>\n",
       "      <td>Lack awareness pervasiveness racism society pr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>7997</td>\n",
       "      <td>Why are aspirins white? Because they work sorry</td>\n",
       "      <td>1</td>\n",
       "      <td>1.33</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.85</td>\n",
       "      <td>8</td>\n",
       "      <td>aspirin white ? work sorry</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>7998</td>\n",
       "      <td>Today, we Americans celebrate our independence...</td>\n",
       "      <td>1</td>\n",
       "      <td>2.55</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>14</td>\n",
       "      <td>Today , Americans celebrate independence Brita...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>7999</td>\n",
       "      <td>How to keep the flies off the bride at an Ital...</td>\n",
       "      <td>1</td>\n",
       "      <td>1.00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.00</td>\n",
       "      <td>20</td>\n",
       "      <td>keep fly bride Italian wedding Keep bucket shi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>8000</td>\n",
       "      <td>\"Each ounce of sunflower seeds gives you 37% o...</td>\n",
       "      <td>0</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0.00</td>\n",
       "      <td>17</td>\n",
       "      <td>`` ounce sunflower seed give 37 % daily need v...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        id                                               text  is_humor  \\\n",
       "0        1  TENNESSEE: We're the best state. Nobody even c...         1   \n",
       "1        2  A man inserted an advertisement in the classif...         1   \n",
       "2        3  How many men does it take to open a can of bee...         1   \n",
       "3        4  Told my mom I hit 1200 Twitter followers. She ...         1   \n",
       "4        5  Roses are dead. Love is fake. Weddings are bas...         1   \n",
       "...    ...                                                ...       ...   \n",
       "7995  7996  Lack of awareness of the pervasiveness of raci...         0   \n",
       "7996  7997    Why are aspirins white? Because they work sorry         1   \n",
       "7997  7998  Today, we Americans celebrate our independence...         1   \n",
       "7998  7999  How to keep the flies off the bride at an Ital...         1   \n",
       "7999  8000  \"Each ounce of sunflower seeds gives you 37% o...         0   \n",
       "\n",
       "      humor_rating  humor_controversy  offense_rating  sentence_length  \\\n",
       "0             2.42                1.0            0.20               17   \n",
       "1             2.50                1.0            1.10               32   \n",
       "2             1.95                0.0            2.40               26   \n",
       "3             2.11                1.0            0.00               26   \n",
       "4             2.78                0.0            0.10               12   \n",
       "...            ...                ...             ...              ...   \n",
       "7995           NaN                NaN            0.25               27   \n",
       "7996          1.33                0.0            3.85                8   \n",
       "7997          2.55                0.0            0.00               14   \n",
       "7998          1.00                0.0            3.00               20   \n",
       "7999           NaN                NaN            0.00               17   \n",
       "\n",
       "                                         processed_text  \n",
       "0     TENNESSEE : 're best state . Nobody even come ...  \n",
       "1     man inserted advertisement classified `` Wife ...  \n",
       "2     many men take open beer ? None . open time bri...  \n",
       "3     Told mom hit 1200 Twitter follower . pointed b...  \n",
       "4     Roses dead . Love fake . Weddings basically fu...  \n",
       "...                                                 ...  \n",
       "7995  Lack awareness pervasiveness racism society pr...  \n",
       "7996                         aspirin white ? work sorry  \n",
       "7997  Today , Americans celebrate independence Brita...  \n",
       "7998  keep fly bride Italian wedding Keep bucket shi...  \n",
       "7999  `` ounce sunflower seed give 37 % daily need v...  \n",
       "\n",
       "[8000 rows x 8 columns]"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "0505be18",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    data['processed_text'], \n",
    "    data['is_humor'], \n",
    "    test_size=0.2, \n",
    "    random_state=42\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "92881f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Word2Vec model training\n",
    "word2vec_model = Word2Vec(sentences=X_train.apply(word_tokenize), vector_size=100, window=5, min_count=1, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96bd4997",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to average word vectors for a sentence\n",
    "def average_word_vectors(words, model, vocabulary, num_features):\n",
    "    feature_vector = np.zeros((num_features,), dtype=\"float32\")\n",
    "    n_words = 0\n",
    "    for word in words:\n",
    "        if word in vocabulary:\n",
    "            n_words += 1\n",
    "            feature_vector = np.add(feature_vector, model.wv[word])\n",
    "    if n_words:\n",
    "        feature_vector = np.divide(feature_vector, n_words)\n",
    "    return feature_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "1a77699c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transform text data to Word2Vec features\n",
    "def word2vec_features(data, model, num_features):\n",
    "    vocabulary = set(model.wv.index_to_key)\n",
    "    return np.vstack([average_word_vectors(tokens, model, vocabulary, num_features) for tokens in data.apply(word_tokenize)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "2d46521b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# SVC model\n",
    "svc_model = SVC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "22bbf5fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a pipeline with Word2Vec and SVC\n",
    "model_pipeline = Pipeline([\n",
    "    ('word2vec', FunctionTransformer(lambda x: word2vec_features(x, word2vec_model, 100))),\n",
    "    ('svc', svc_model)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "05fc7a2d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>Pipeline(steps=[(&#x27;word2vec&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x143e9d760&gt;)),\n",
       "                (&#x27;svc&#x27;, SVC())])</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item sk-dashed-wrapped\"><div class=\"sk-label-container\"><div class=\"sk-label sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" ><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">Pipeline</label><div class=\"sk-toggleable__content\"><pre>Pipeline(steps=[(&#x27;word2vec&#x27;,\n",
       "                 FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x143e9d760&gt;)),\n",
       "                (&#x27;svc&#x27;, SVC())])</pre></div></div></div><div class=\"sk-serial\"><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" ><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">FunctionTransformer</label><div class=\"sk-toggleable__content\"><pre>FunctionTransformer(func=&lt;function &lt;lambda&gt; at 0x143e9d760&gt;)</pre></div></div></div><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-3\" type=\"checkbox\" ><label for=\"sk-estimator-id-3\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC()</pre></div></div></div></div></div></div></div>"
      ],
      "text/plain": [
       "Pipeline(steps=[('word2vec',\n",
       "                 FunctionTransformer(func=<function <lambda> at 0x143e9d760>)),\n",
       "                ('svc', SVC())])"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Train the model\n",
    "model_pipeline.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "fb43e0f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.63\n",
      "F1 Score: 0.76\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model\n",
    "predictions = model_pipeline.predict(X_test)\n",
    "accuracy = accuracy_score(y_test, predictions)\n",
    "f1 = f1_score(y_test, predictions)\n",
    "\n",
    "print(f\"Accuracy: {accuracy:.2f}\")\n",
    "print(f\"F1 Score: {f1:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "8f86fa0f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2215    1\n",
       "2582    1\n",
       "1662    1\n",
       "3027    0\n",
       "4343    1\n",
       "       ..\n",
       "1079    0\n",
       "7979    1\n",
       "1115    0\n",
       "6093    1\n",
       "6832    1\n",
       "Name: is_humor, Length: 1600, dtype: int64"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "eae03cc8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of zeros: 121\n",
      "Number of ones: 1479\n"
     ]
    }
   ],
   "source": [
    "count_zeros = (predictions == 0).sum()\n",
    "count_ones = (predictions == 1).sum()\n",
    "\n",
    "print(f\"Number of zeros: {count_zeros}\")\n",
    "print(f\"Number of ones: {count_ones}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "9ef6079a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ulazni tekst koji želite predvidjeti\n",
    "input_text = \"I am so funny. Am I?\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "b0d4a141",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primijenite istu predobradu teksta\n",
    "processed_input = preprocess_text(input_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "c9d19a54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pretvorite tekst u vektor\n",
    "input_vector = average_word_vectors(processed_input, word2vec_model, set(word2vec_model.wv.index_to_key), 100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "5786f811",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shape of input vector: (100,)\n"
     ]
    }
   ],
   "source": [
    "# Provjerite oblik vektora (provjerite dimenzionalnost)\n",
    "print(\"Shape of input vector:\", input_vector.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "36bbb8a0",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'list' object has no attribute 'apply'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[81], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Obavite predikciju\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m prediction \u001b[38;5;241m=\u001b[39m model_pipeline\u001b[38;5;241m.\u001b[39mpredict([input_vector])\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Ispis rezultata\u001b[39;00m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPredicted class:\u001b[39m\u001b[38;5;124m\"\u001b[39m, prediction)\n",
      "File \u001b[0;32m~/miniconda3/envs/ba-project-semeval22/lib/python3.11/site-packages/sklearn/pipeline.py:514\u001b[0m, in \u001b[0;36mPipeline.predict\u001b[0;34m(self, X, **predict_params)\u001b[0m\n\u001b[1;32m    512\u001b[0m Xt \u001b[38;5;241m=\u001b[39m X\n\u001b[1;32m    513\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, name, transform \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_iter(with_final\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m):\n\u001b[0;32m--> 514\u001b[0m     Xt \u001b[38;5;241m=\u001b[39m transform\u001b[38;5;241m.\u001b[39mtransform(Xt)\n\u001b[1;32m    515\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msteps[\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m][\u001b[38;5;241m1\u001b[39m]\u001b[38;5;241m.\u001b[39mpredict(Xt, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mpredict_params)\n",
      "File \u001b[0;32m~/miniconda3/envs/ba-project-semeval22/lib/python3.11/site-packages/sklearn/utils/_set_output.py:157\u001b[0m, in \u001b[0;36m_wrap_method_output.<locals>.wrapped\u001b[0;34m(self, X, *args, **kwargs)\u001b[0m\n\u001b[1;32m    155\u001b[0m \u001b[38;5;129m@wraps\u001b[39m(f)\n\u001b[1;32m    156\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mwrapped\u001b[39m(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[0;32m--> 157\u001b[0m     data_to_wrap \u001b[38;5;241m=\u001b[39m f(\u001b[38;5;28mself\u001b[39m, X, \u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data_to_wrap, \u001b[38;5;28mtuple\u001b[39m):\n\u001b[1;32m    159\u001b[0m         \u001b[38;5;66;03m# only wrap the first output for cross decomposition\u001b[39;00m\n\u001b[1;32m    160\u001b[0m         return_tuple \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    161\u001b[0m             _wrap_data_with_container(method, data_to_wrap[\u001b[38;5;241m0\u001b[39m], X, \u001b[38;5;28mself\u001b[39m),\n\u001b[1;32m    162\u001b[0m             \u001b[38;5;241m*\u001b[39mdata_to_wrap[\u001b[38;5;241m1\u001b[39m:],\n\u001b[1;32m    163\u001b[0m         )\n",
      "File \u001b[0;32m~/miniconda3/envs/ba-project-semeval22/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:240\u001b[0m, in \u001b[0;36mFunctionTransformer.transform\u001b[0;34m(self, X)\u001b[0m\n\u001b[1;32m    226\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"Transform X using the forward function.\u001b[39;00m\n\u001b[1;32m    227\u001b[0m \n\u001b[1;32m    228\u001b[0m \u001b[38;5;124;03mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    237\u001b[0m \u001b[38;5;124;03m    Transformed input.\u001b[39;00m\n\u001b[1;32m    238\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    239\u001b[0m X \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_check_input(X, reset\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m--> 240\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_transform(X, func\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc, kw_args\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkw_args)\n",
      "File \u001b[0;32m~/miniconda3/envs/ba-project-semeval22/lib/python3.11/site-packages/sklearn/preprocessing/_function_transformer.py:312\u001b[0m, in \u001b[0;36mFunctionTransformer._transform\u001b[0;34m(self, X, func, kw_args)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m func \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    310\u001b[0m     func \u001b[38;5;241m=\u001b[39m _identity\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(X, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39m(kw_args \u001b[38;5;28;01mif\u001b[39;00m kw_args \u001b[38;5;28;01melse\u001b[39;00m {}))\n",
      "Cell \u001b[0;32mIn[52], line 3\u001b[0m, in \u001b[0;36m<lambda>\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Create a pipeline with Word2Vec and SVC\u001b[39;00m\n\u001b[1;32m      2\u001b[0m model_pipeline \u001b[38;5;241m=\u001b[39m Pipeline([\n\u001b[0;32m----> 3\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mword2vec\u001b[39m\u001b[38;5;124m'\u001b[39m, FunctionTransformer(\u001b[38;5;28;01mlambda\u001b[39;00m x: word2vec_features(x, word2vec_model, \u001b[38;5;241m100\u001b[39m))),\n\u001b[1;32m      4\u001b[0m     (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msvc\u001b[39m\u001b[38;5;124m'\u001b[39m, svc_model)\n\u001b[1;32m      5\u001b[0m ])\n",
      "Cell \u001b[0;32mIn[50], line 4\u001b[0m, in \u001b[0;36mword2vec_features\u001b[0;34m(data, model, num_features)\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mword2vec_features\u001b[39m(data, model, num_features):\n\u001b[1;32m      3\u001b[0m     vocabulary \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mset\u001b[39m(model\u001b[38;5;241m.\u001b[39mwv\u001b[38;5;241m.\u001b[39mindex_to_key)\n\u001b[0;32m----> 4\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m np\u001b[38;5;241m.\u001b[39mvstack([average_word_vectors(tokens, model, vocabulary, num_features) \u001b[38;5;28;01mfor\u001b[39;00m tokens \u001b[38;5;129;01min\u001b[39;00m data\u001b[38;5;241m.\u001b[39mapply(word_tokenize)])\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'list' object has no attribute 'apply'"
     ]
    }
   ],
   "source": [
    "# Obavite predikciju\n",
    "input_vector_2d = input_vector.reshape(1, -1)\n",
    "prediction = model_pipeline.predict([input_vector])\n",
    "\n",
    "# Ispis rezultata\n",
    "print(\"Predicted class:\", prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4272c718",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
